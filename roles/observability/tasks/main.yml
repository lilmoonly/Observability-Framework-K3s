---
# tasks file for observability role to deploy the observability stack

- name: Ensure Helm is installed on master
  become: true
  delegate_to: k8s-ctrl
  ansible.builtin.shell: |
    curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
  args:
    creates: /usr/local/bin/helm

- name: Add Helm repos for OpenSearch, Prometheus, and CloudNativePG
  become: true
  delegate_to: k8s-ctrl
  ansible.builtin.shell: |
    export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
    /usr/local/bin/helm repo add opensearch https://opensearch-project.github.io/helm-charts/
    /usr/local/bin/helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
    /usr/local/bin/helm repo add cnpg https://cloudnative-pg.github.io/charts
    /usr/local/bin/helm repo update

- name: Deploy OpenSearch via Helm
  become: true
  delegate_to: k8s-ctrl
  community.kubernetes.helm:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    name: opensearch
    chart_ref: opensearch/opensearch
    release_namespace: opensearch
    create_namespace: true
    wait: yes
    timeout: 1200s
    values:
      persistence:
        enabled: true
        storageClass: "{{ storage.storage_class }}"
      singleNode: true
      securityConfig:
        enabled: true
      extraEnvs:
        - name: OPENSEARCH_INITIAL_ADMIN_PASSWORD
          value: "{{ opensearch.admin_password }}"
        - name: node.store.allow_mmap
          value: "false"
        - name: OPENSEARCH_JAVA_OPTS
          value: "-Xmx{{ opensearch.heap_size }} -Xms{{ opensearch.heap_size }}"
      nodeSelector:
        workload: "{{ opensearch.node_selector_label }}"
      tolerations:
        - key: "workload"
          operator: "Equal"
          value: "{{ opensearch.node_selector_label }}"
          effect: "NoSchedule"
      resources:
        requests:
          memory: 512Mi
          cpu: 200m
        limits:
          memory: 2Gi
          cpu: 1000m
      startupProbe:
        tcpSocket:
          port: 9200
        initialDelaySeconds: 90
        periodSeconds: 10
        failureThreshold: 60
      readinessProbe:
        tcpSocket:
          port: 9200
        initialDelaySeconds: 60
        periodSeconds: 10
        failureThreshold: 10

- name: Deploy OpenSearch Dashboards via Helm
  become: true
  delegate_to: k8s-ctrl
  community.kubernetes.helm:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    name: opensearch-dashboards
    chart_ref: opensearch/opensearch-dashboards
    release_namespace: opensearch
    create_namespace: true
    wait: yes
    timeout: 1200s
    values:
      opensearchHosts: "https://opensearch-cluster-master:9200"
      config:
        录取opensearch_dashboards.yml:
          server.host: "0.0.0.0"
          opensearch.ssl.verificationMode: none
          opensearch.username: "admin"
          opensearch.password: "{{ opensearch.admin_password }}"
          opensearch.requestHeadersWhitelist: [ "authorization", "securitytenant" ]
      service:
        type: LoadBalancer
        port: "{{ opensearch_dashboards_port }}"
      nodeSelector:
        workload: "logging"
      tolerations:
        - key: "workload"
          operator: "Equal"
          value: "logging"
          effect: "NoSchedule"
      resources:
        limits:
          memory: 512Mi
          cpu: 500m
      startupProbe:
        tcpSocket:
          port: 5601
        initialDelaySeconds: 60
        periodSeconds: 10
        failureThreshold: 20

- name: Deploy kube-prometheus-stack via Helm
  become: true
  delegate_to: k8s-ctrl
  community.kubernetes.helm:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    name: prometheus
    chart_ref: prometheus-community/kube-prometheus-stack
    release_namespace: monitoring
    create_namespace: true
    wait: yes
    timeout: 1200s
    values:
      prometheus:
        prometheusSpec:
          retention: "{{ monitoring.prometheus_retention }}"
          storageSpec:
            volumeClaimTemplate:
              spec:
                storageClassName: "{{ storage.storage_class }}"
                accessModes: [ "ReadWriteOnce" ]
                resources:
                  requests:
                    storage: "{{ storage.prometheus_size }}"
          resources:
            requests:
              memory: 512Mi
              cpu: 200m
            limits:
              memory: 1Gi
              cpu: 1000m
      grafana:
        adminPassword: "{{ monitoring.grafana_admin_password }}"
        service:
          type: LoadBalancer
          port: "{{ grafana_port }}"
      nodeSelector:
        workload: "{{ monitoring.node_selector_label }}"
      tolerations:
        - key: "workload"
          operator: "Equal"
          value: "{{ monitoring.node_selector_label }}"
          effect: "NoSchedule"

- name: Install CloudNativePG operator via Helm
  become: true
  delegate_to: k8s-ctrl
  community.kubernetes.helm:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    name: cnpg-operator
    chart_ref: cnpg/cloudnative-pg
    release_namespace: cnpg-system
    create_namespace: true
    wait: yes

- name: Taint worker nodes for observability workloads
  become: true
  delegate_to: k8s-ctrl
  ansible.builtin.shell: |
    export KUBECONFIG=/etc/rancher/k3s/k3s.yaml
    kubectl taint nodes app-worker workload=app:NoSchedule --overwrite
    kubectl taint nodes db-worker workload=db:NoSchedule --overwrite
    kubectl taint nodes logging-node workload=logging:NoSchedule --overwrite
    kubectl taint nodes monitor-node workload=monitoring:NoSchedule --overwrite
    kubectl taint nodes ai-node workload=ai:NoSchedule --overwrite

- name: Create db namespace
  become: true
  delegate_to: k8s-ctrl
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    state: present
    definition:
      apiVersion: v1
      kind: Namespace
      metadata:
        name: db

- name: Create app-db-secret in db namespace
  become: true
  delegate_to: k8s-ctrl
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    state: present
    definition:
      apiVersion: v1
      kind: Secret
      metadata:
        name: app-db-secret
        namespace: db
      type: Opaque
      data:
        username: "{{ 'appuser' | b64encode }}"
        password: "{{ 'appuserpassword' | b64encode }}"

- name: Deploy PostgreSQL Cluster resource (HA)
  become: true
  delegate_to: k8s-ctrl
  kubernetes.core.k8s:
    kubeconfig: /etc/rancher/k3s/k3s.yaml
    state: present
    definition:
      apiVersion: postgresql.cnpg.io/v1
      kind: Cluster
      metadata:
        name: "{{ database.cluster_name }}"
        namespace: db
      spec:
        instances: "{{ replicas.postgres }}" 
        storage:
          size: "{{ storage.postgres_size }}"
          storageClass: "{{ storage.storage_class }}"
        nodeSelector:
          workload: "{{ database.node_selector_label }}"
        tolerations:
          - key: "workload"
            operator: "Equal"
            value: "{{ database.node_selector_label }}"
            effect: "NoSchedule"
        bootstrap:
          initdb:
            database: app
            owner: appuser
            secret:
              name: app-db-secret
        superuserSecret:
          name: app-db-secret
        enableSuperuserAccess: true
    wait: yes